# API key â€” copy to .env and add your key. Use locally only; never commit .env or push to GitHub.
GEMINI_API_KEY=

# Timeout in seconds for each Gemini API request (default 120). Pro models auto-use at least 300s.
# GEMINI_TIMEOUT=120

# Min timeout for Pro models (default 300). Override if needed.
# GEMINI_TIMEOUT_PRO_MIN=300

# Retry attempts for transient failures (default 2). Set 0 to disable.
# GEMINI_RETRY_ATTEMPTS=2

# Max parallel blocks when expanding (default: 2 for Gemini, 6 for local). Lower to 1 if you hit 429 rate limits.
# With high-end GPU (>=8GB VRAM), local default is 12.
# EXPANDER_MAX_CONCURRENT=2

# Force aggressive local training when high-end GPU detected: 1=on, 0=off (auto-detect if unset).
# Disabled when on battery to avoid drain.
# EXPANDER_AGGRESSIVE_LOCAL=

# Allow aggressive training on battery (default: off). Set 1 to override.
# EXPANDER_AGGRESSIVE_ON_BATTERY=

# VRAM threshold in MB for "high-end" (default 8192). GPU with >= this triggers aggressive protocol.
# EXPANDER_GPU_VRAM_MB=8192

# Ollama request timeout in seconds (default 120). Used for --backend local.
# OLLAMA_TIMEOUT=120
